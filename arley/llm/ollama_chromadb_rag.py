import difflib
import os
import textwrap
from pathlib import Path

from typing import Literal, Optional, Tuple, TextIO

import chromadb
from jinja2 import Environment, FileSystemLoader

from arley import Helper
from arley.config import settings

from arley.config import (TEMPLATEDIRPATH,
                          OllamaPrimingMessage,
                          TemplateType,
                          OLLAMA_MODEL,
                          OLLAMA_FUNCTION_CALLING_MODEL,
                          OLLAMA_GUESS_LANGUAGE_MODEL,
                          CHROMADB_DEFAULT_COLLECTION_NAME,
                          ARLEY_AUG_UNIFIED,
                          ARLEY_AUG_PER_ITEM,
                          ARLEY_AUG_NUM_DOCS,
                          ARLEY_AUG_TEMPLATE_TYPE,
                          ARLEY_AUG_ONLY_CONTRACTS,
                          ARLEY_AUG_LANG_FILTER,
                          ARLEY_AUG_FIRST_REQUEST_INCLUDE_AUG,
                          ARLEY_AUG_FIRST_REQUEST_UNIFIED,
                          ARLEY_AUG_FIRST_REQUEST_PER_ITEM,
                          ARLEY_AUG_FIRST_REQUEST_TEMPLATE_TYPE,
                          ARLEY_AUG_FIRST_REQUEST_N_AUG_RESULTS,
                          ARLEY_AUG_FIRST_REQUEST_AUG_ONLY_CONTRACTS,
                          ARLEY_AUG_FIRST_REQUEST_AUG_LANG_FILTER,
                          REFINELOG_RECIPIENTS, OLLAMA_HOST, get_ollama_options)

import datetime
from io import StringIO

import pytz

from arley.llm.ollama_adapter import (
    Message,
    ask_ollama_chat
)

from loguru import logger

from arley.vectorstore.chroma_adapter import ChromaDBConnection

_timezone: datetime.tzinfo = pytz.timezone(settings.timezone)



class OllamaChromaDBRAG:
    logger = logger.bind(classname=__qualname__)

    def __init__(self, cdbcollection: chromadb.api.models.Collection.Collection):
        self.cdbcollection = cdbcollection

    def get_refine_contexts(self,
                            prompt: str,
                            lang: Literal["de", "en"],
                            n_aug_results: int = ARLEY_AUG_NUM_DOCS,
                            template_type: TemplateType = ARLEY_AUG_TEMPLATE_TYPE,
                            unified_aug: bool = ARLEY_AUG_UNIFIED,
                            refine_per_item: bool = ARLEY_AUG_PER_ITEM,
                            aug_only_contracts: bool = ARLEY_AUG_ONLY_CONTRACTS,
                            aug_lang_filter: bool = ARLEY_AUG_LANG_FILTER,
                            is_initial_aug_request: bool = False,
                            refinelog: StringIO|TextIO|None = None) -> list[Tuple[str, str]]:


        logger = self.__class__.logger

        context_aug: dict[str, list[dict]] = ChromaDBConnection.get_context_augmentations(
            initial_topic=None,  # initial_topic,
            prompt=prompt,
            lang=lang if aug_lang_filter else None,
            cdbcollection=self.cdbcollection,
            n_results=n_aug_results,
            only_contracts=aug_only_contracts
        )
        logger.debug(f"CONTEXT_AUG:\n{Helper.get_pretty_dict_json_no_sort(context_aug)}")
        if refinelog:
            refinelog.write(
                f"\n\n\n\n################\nCONTEXT_AUG:\n{Helper.get_pretty_dict_json_no_sort(context_aug)}")

        refines: list[Tuple[str, str]]
        if unified_aug:
            context_str: str = self.get_all_in_context_str(
                lang=lang,
                augments=context_aug,
                template_type=template_type,
                is_initial_aug_request=is_initial_aug_request
            )
            refines = [("ALL", context_str)]
        else:
            refines = self.get_context_refines(
                lang=lang,
                augments=context_aug,
                template_type=template_type,
                per_item=refine_per_item,
                is_initial_aug_request=is_initial_aug_request
            )

        return refines


    def refine_response(self,
                        initial_topic: str,
                        prompt: str,
                        existing_response: str,
                        lang: Literal["en", "de"],
                        primer: list,
                        ollama_model: str = OLLAMA_MODEL,
                        streamed: bool=False,
                        temperature: float=0.1,
                        n_aug_results: int = ARLEY_AUG_NUM_DOCS,
                        template_type: TemplateType = ARLEY_AUG_TEMPLATE_TYPE,
                        unified_aug: bool = ARLEY_AUG_UNIFIED,
                        refine_per_item: bool = ARLEY_AUG_PER_ITEM,
                        aug_only_contracts: bool = ARLEY_AUG_ONLY_CONTRACTS,
                        aug_lang_filter: bool = ARLEY_AUG_LANG_FILTER,
                        is_initial_aug_request: bool = False,
                        is_history_mode: bool = False,
                        refinelog: StringIO|TextIO|None = None,
                        print_msgs: bool = False,
                        print_response: bool =False,
                        ) -> str:

        logger = self.__class__.logger


        if n_aug_results <= 0:
            return existing_response

        refines: list[Tuple[str, str]] = self.get_refine_contexts(prompt=prompt,
                                                                 lang=lang,
                                                                 n_aug_results=n_aug_results,
                                                                 template_type=template_type,
                                                                 refine_per_item=refine_per_item,
                                                                 aug_only_contracts=aug_only_contracts,
                                                                 aug_lang_filter=aug_lang_filter,
                                                                 is_initial_aug_request=is_initial_aug_request,
                                                                 unified_aug=unified_aug,
                                                                 refinelog=refinelog)

        if len(refines) == 0:
            return existing_response

        notelines: list[str|None] = []

        refined_response_txt: str = existing_response
        refined_response_txt_wo_think_tag: str
        refined_response_txt_think_tag: str|None

        refined_response_txt_wo_think_tag, refined_response_txt_think_tag = Helper.detach_think_tag(existing_response)

        for refine_type, merefine in refines:
            refined_prompt: str = self.get_refine_prompt(
                original_prompt=prompt,
                existing_response=refined_response_txt_wo_think_tag,
                context=merefine,
                ollama_model=ollama_model,
                lang=lang,
                template_type=template_type,
                is_initial_aug_request=is_initial_aug_request
            )

            logger.debug(f"refined prompt ({refine_type=}):\n{textwrap.indent(refined_prompt, "  Q  ")}")

            if refinelog:
                refinelog.write(f"\n\n\n\n################\nREFINED PROMPT ({refine_type=}):\n{refined_prompt}")

            # wenn ich chatmode bin, muÃŸ ich die letzte nachricht austauschen -> sonst wird die nicht besser


            resp_refined: dict = ask_ollama_chat(
                system_prompt=None,  # need to provide msg_history then
                prompt=refined_prompt,
                msg_history=primer,
                model=ollama_model,
                evict=False,
                temperature=temperature,
                # penalize_newline=True,
                # repeat_penalty=1.0,
                top_k=40,
                top_p=0.9,
                num_predict=-1,
                seed=0,
                print_msgs=print_msgs,
                print_response=print_response,
                print_options=False,
                max_tries_ollama_done_response=21,
                streamed=streamed,
                print_chunks_when_streamed=False
            )

            refined_response_txt_b: str = refined_response_txt
            refined_response_txt_wo_think_tag_b: str = refined_response_txt_wo_think_tag

            # TODO !!!

            refined_response_txt = resp_refined["message"]["content"]
            refined_response_txt_wo_think_tag, refined_response_txt_think_tag = Helper.detach_think_tag(refined_response_txt)

            noteline: Optional[str]
            refined_response_txt_wo_think_tag, noteline = Helper.detach_NOTE_line(refined_response_txt_wo_think_tag)
            notelines.append(noteline)

            if is_history_mode:
                primer[-1]["content"] = refined_response_txt_wo_think_tag

            logger.debug(f"refined_response_txt_think_tag ({refine_type=}):\n{textwrap.indent(refined_response_txt_think_tag, "  R  ")}")
            logger.debug(f"refined_response_txt ({refine_type=}):\n{textwrap.indent(refined_response_txt_wo_think_tag, "  R  ")}")
            logger.debug(f"refined_response_txt ({refine_type=}) NOTELINE:\n{textwrap.indent(f"{noteline}", "  R  ")}")

            if refinelog and not refine_type == "ALL":
                # f"refined_response_txt ({refine_type=}):\n{textwrap.indent(refined_response_txt, "  R  ")}"
                refinelog.write(f"\nrefined_response_txt ({refine_type=}) NOTE:\n{textwrap.indent(f"{noteline}", "  R  ")}\n")

                diff_str: StringIO = StringIO()
                for l in difflib.unified_diff(refined_response_txt_wo_think_tag_b, refined_response_txt_wo_think_tag,
                                              fromfile=f"BEFORE_{refine_type}", tofile=f"AFTER_{refine_type}"):
                    diff_str.write(l)

                refinelog.write(f"\n\n################\nDIFF_{refine_type}:\n{diff_str.getvalue()}")


        if refinelog:
            refinelog.write(f"\n\n\n\n################\nEXISTING RESPONSE TEXT:\n{textwrap.indent(existing_response, "  I  ")}")
            refinelog.write(f"\n\n\n\n################\nREFINED RESPONSE TEXT:\n{textwrap.indent(refined_response_txt, "  R  ")}")  # including think-tag!

            notelines_str: StringIO = StringIO()
            for i in range(0, len(notelines)):
                if i > 1:
                    notelines_str.write("\n")
                notelines_str.write(textwrap.indent(f"[{i+1}] {notelines[i]}\n", "  RN "))

            refinelog.write(f"\nREFINED RESPONSE TEXT NOTELINES:\n{notelines_str.getvalue()}")

            diff_str: StringIO = StringIO()
            for l in difflib.unified_diff(existing_response, refined_response_txt_wo_think_tag,
                                          fromfile="B", tofile="A"):
                diff_str.write(l)

            refinelog.write(f"\n\n\n\n################\nDIFF:\n{diff_str.getvalue()}")

        return refined_response_txt_wo_think_tag


    def get_refine_prompt(self,
            original_prompt: str,
            existing_response: str | None,
            context: str,
            ollama_model: str | None = None,
            lang: Literal["en", "de"] = "en",
            template_type: TemplateType = TemplateType.plain,
            is_initial_aug_request: bool = False) -> str:

        # https://docs.llamaindex.ai/en/stable/examples/prompts/prompt_mixin/

        tname: str = f"refine_prompt_{lang}_{template_type.value}.jinja"
        if is_initial_aug_request:
            tname: str = f"aug_initial_prompt_{lang}_{template_type.value}.jinja"

        fp: Path = Path(TEMPLATEDIRPATH, template_type.value)
        fp = Path(fp, tname)

        with open(fp) as file_:
            template = Environment(loader=FileSystemLoader(fp.parent), trim_blocks=True,
                                   lstrip_blocks=True).from_string(file_.read())

        values: dict = {
            "lang": lang,
            "original_prompt": original_prompt,
            "existing_response": existing_response,
            "context": context,
            "ollama_model": ollama_model,
            "is_initial_request": is_initial_aug_request,
            "template_type": template_type.value
        }

        ret: str = template.render(values)
        return ret

    def get_context_refines(self,
            lang: Literal["de", "en"],
            augments: dict[str, list[dict]],
            ollama_model: str | None = None,
            template_type: TemplateType = TemplateType.plain,
            per_item: bool = True,
            is_initial_aug_request: bool = False,
            prompt: str | None = None
    ) -> list[Tuple[str, str]]:

        ret: list[Tuple[str, str]] = []

        tname: str = f"get_context_{lang}_{template_type.value}.jinja"
        if is_initial_aug_request:
            tname = f"aug_initial_prompt_context_{lang}_{template_type.value}.jinja"

        fp: Path = Path(TEMPLATEDIRPATH, template_type.value)
        fp = Path(fp, tname)

        with open(fp) as file_:
            template = Environment(loader=FileSystemLoader(fp.parent), trim_blocks=True,
                                   lstrip_blocks=True).from_string(file_.read())

        for refine_type in ["contract_outline", "contract_summary", "contract_excerpt",
                            "contract"]:  # context_aug.keys():
            merefine: list[dict] | None = augments.get(refine_type)
            if not merefine:
                logger.debug(f"SKIP: {refine_type}")
                continue

            logger.debug(f"FOUND: {refine_type}")

            values: dict = {
                "lang": lang,
                "refine_type": refine_type,
                "merefine": merefine,
                "ollama_model": ollama_model,
                "prompt": prompt,
                "template_type": template_type.value
            }

            if per_item:
                for merefine_one in merefine:
                    values["merefine"] = [merefine_one]

                    ret.append(
                        (
                            refine_type,
                            template.render(values)
                        )
                    )
            else:
                ret.append(
                    (
                        refine_type,
                        template.render(values)
                    )
                )

        return ret

    def get_all_in_context_str(self,
            lang: Literal["de", "en"],
            augments: dict[str, list[dict]],
            ollama_model: str | None = None,
            template_type: TemplateType = TemplateType.plain,
            is_initial_aug_request: bool = False) -> str:

        ret: StringIO = StringIO()

        refines: list[Tuple[str, str]] = self.get_context_refines(
            lang=lang,
            augments=augments,
            template_type=template_type,
            ollama_model=ollama_model,
            per_item=False,
            is_initial_aug_request=is_initial_aug_request
        )

        for refine_type, merefine in refines:
            ret.write(merefine.strip())
            ret.write("\n\n")

        return ret.getvalue().strip()